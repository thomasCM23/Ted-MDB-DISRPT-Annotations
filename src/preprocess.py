# Preprocess the raw data to create the .conllu, and .tok files, these files will not have discourse connective annotations
# For .conllu we need to split the sentences and tokenize, this will be done using spacy and conllu packages
# for .tok we we need to tokenize, this will be done using spacy
# 

